{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "suffering-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "concrete-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_df = pd.read_csv('.../kddpretrainPre.csv')\n",
    "Normal_df_test = pd.read_csv('.../kddpretestPre.csv')\n",
    "DoS_df = pd.read_csv('.../kddpretraindos.csv')\n",
    "DoS_df_test = pd.read_csv('.../kddpretestdos.csv')\n",
    "Probe_df = pd.read_csv('.../kddpretrainProb.csv')\n",
    "Probe_df_test = pd.read_csv('.../kddpretestProb.csv')\n",
    "R2L_df = pd.read_csv('.../kddpretrainR2L.csv')\n",
    "R2L_df_test = pd.read_csv('.../kddpretestR2l.csv')\n",
    "U2R_df = pd.read_csv('.../kddpretrainU2R.csv')\n",
    "U2R_df_test = pd.read_csv('.../kddpretestU2R.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "center-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Normal = Normal_df.drop('label',1)\n",
    "Y_Normal = Normal_df.label\n",
    "X_DoS = DoS_df.drop('label',1)\n",
    "Y_DoS = DoS_df.label\n",
    "X_Probe = Probe_df.drop('label',1)\n",
    "Y_Probe = Probe_df.label\n",
    "X_R2L = R2L_df.drop('label',1)\n",
    "Y_R2L = R2L_df.label\n",
    "X_U2R = U2R_df.drop('label',1)\n",
    "Y_U2R = U2R_df.label\n",
    "# test set\n",
    "X_Normal_test = Normal_df_test.drop('label',1)\n",
    "Y_Normal_test = Normal_df_test.label\n",
    "X_DoS_test = DoS_df_test.drop('label',1)\n",
    "Y_DoS_test = DoS_df_test.label\n",
    "X_Probe_test = Probe_df_test.drop('label',1)\n",
    "Y_Probe_test = Probe_df_test.label\n",
    "X_R2L_test = R2L_df_test.drop('label',1)\n",
    "Y_R2L_test = R2L_df_test.label\n",
    "X_U2R_test = U2R_df_test.drop('label',1)\n",
    "Y_U2R_test = U2R_df_test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "phantom-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "colNames=list(X_DoS)\n",
    "colNames_test=list(X_DoS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sought-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler0 = preprocessing.StandardScaler().fit(X_Normal)\n",
    "X_Normal=scaler0.transform(X_Normal) \n",
    "scaler1 = preprocessing.StandardScaler().fit(X_DoS)\n",
    "X_DoS=scaler1.transform(X_DoS) \n",
    "scaler2 = preprocessing.StandardScaler().fit(X_Probe)\n",
    "X_Probe=scaler2.transform(X_Probe) \n",
    "scaler3 = preprocessing.StandardScaler().fit(X_R2L)\n",
    "X_R2L=scaler3.transform(X_R2L) \n",
    "scaler4 = preprocessing.StandardScaler().fit(X_U2R)\n",
    "X_U2R=scaler4.transform(X_U2R) \n",
    "\n",
    "scaler9 = preprocessing.StandardScaler().fit(X_Normal_test)\n",
    "X_Normal_test=scaler9.transform(X_Normal_test) \n",
    "scaler5 = preprocessing.StandardScaler().fit(X_DoS_test)\n",
    "X_DoS_test=scaler5.transform(X_DoS_test) \n",
    "scaler6 = preprocessing.StandardScaler().fit(X_Probe_test)\n",
    "X_Probe_test=scaler6.transform(X_Probe_test) \n",
    "scaler7 = preprocessing.StandardScaler().fit(X_R2L_test)\n",
    "X_R2L_test=scaler7.transform(X_R2L_test) \n",
    "scaler8 = preprocessing.StandardScaler().fit(X_U2R_test)\n",
    "X_U2R_test=scaler8.transform(X_U2R_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "governing-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Normal.std(axis=0)\n",
    "X_DoS.std(axis=0)\n",
    "X_Probe.std(axis=0);\n",
    "X_R2L.std(axis=0);\n",
    "X_U2R.std(axis=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "furnished-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "np.seterr(divide='ignore', invalid='ignore');\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(criterion=\"gini\",max_depth=5,random_state=0)\n",
    "rfe = RFE(estimator=clf,n_features_to_select=23, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acting-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.fit(X_Normal, Y_Normal)\n",
    "X_rfeNormal=rfe.transform(X_Normal)\n",
    "X_rfeNormal_test=rfe.transform(X_Normal_test)\n",
    "true=rfe.support_\n",
    "rfecolindex_Normal=[i for i, x in enumerate(true) if x]\n",
    "rfecolname_Normal=list(colNames[i] for i in rfecolindex_Normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tropical-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.fit(X_DoS, Y_DoS)\n",
    "X_rfeDoS=rfe.transform(X_DoS)\n",
    "X_rfeDoS_test=rfe.transform(X_DoS_test)\n",
    "true=rfe.support_\n",
    "rfecolindex_DoS=[i for i, x in enumerate(true) if x]\n",
    "rfecolname_DoS=list(colNames[i] for i in rfecolindex_DoS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "junior-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.fit(X_Probe, Y_Probe)\n",
    "X_rfeProbe=rfe.transform(X_Probe)\n",
    "X_rfeProbe_test=rfe.transform(X_Probe_test)\n",
    "true=rfe.support_\n",
    "rfecolindex_Probe=[i for i, x in enumerate(true) if x]\n",
    "rfecolname_Probe=list(colNames[i] for i in rfecolindex_Probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "outdoor-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.fit(X_R2L, Y_R2L)\n",
    "X_rfeR2L=rfe.transform(X_R2L)\n",
    "X_rfeR2L_test=rfe.transform(X_R2L_test)\n",
    "true=rfe.support_\n",
    "rfecolindex_R2L=[i for i, x in enumerate(true) if x]\n",
    "rfecolname_R2L=list(colNames[i] for i in rfecolindex_R2L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "varying-construction",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.fit(X_U2R, Y_U2R)\n",
    "X_rfeU2R=rfe.transform(X_U2R)\n",
    "X_rfeU2R_test=rfe.transform(X_U2R_test)\n",
    "true=rfe.support_\n",
    "rfecolindex_U2R=[i for i, x in enumerate(true) if x]\n",
    "rfecolname_U2R=list(colNames[i] for i in rfecolindex_U2R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "engaging-sponsorship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=4, random_state=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selected features\n",
    "clf_rfeNormal=DecisionTreeClassifier(max_depth=4,random_state=0)\n",
    "clf_rfeDoS=DecisionTreeClassifier(max_depth=4,random_state=0)\n",
    "clf_rfeProbe=DecisionTreeClassifier(max_depth=4,random_state=0)\n",
    "clf_rfeR2L=DecisionTreeClassifier(max_depth=4,random_state=0)\n",
    "clf_rfeU2R=DecisionTreeClassifier(max_depth=4,random_state=0)\n",
    "\n",
    "clf_rfeNormal.fit(X_rfeNormal, Y_Normal)\n",
    "clf_rfeDoS.fit(X_rfeDoS, Y_DoS)\n",
    "clf_rfeProbe.fit(X_rfeProbe, Y_Probe)\n",
    "clf_rfeR2L.fit(X_rfeR2L, Y_R2L)\n",
    "clf_rfeU2R.fit(X_rfeU2R, Y_U2R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "portuguese-office",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9778, 23)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_Normal_test2=X_Normal_test[:,rfecolindex_Normal]\n",
    "X_DoS_test2=X_DoS_test[:,rfecolindex_DoS]\n",
    "X_Probe_test2=X_Probe_test[:,rfecolindex_Probe]\n",
    "X_R2L_test2=X_R2L_test[:,rfecolindex_R2L]\n",
    "X_U2R_test2=X_U2R_test[:,rfecolindex_U2R]\n",
    "X_U2R_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "strategic-nothing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8409</td>\n",
       "      <td>1150</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>5524</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84</td>\n",
       "      <td>1295</td>\n",
       "      <td>1042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1535</td>\n",
       "      <td>1345</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks     0     1     2\n",
       "Actual attacks                     \n",
       "0                  8409  1150   152\n",
       "1                  1901  5524    35\n",
       "2                    84  1295  1042\n",
       "3                  1535  1345     5\n",
       "4                     7    60     0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Normal_pred2=clf_rfeNormal.predict(X_Normal_test2)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_Normal_test, Y_Normal_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "outdoor-thursday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9432</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2570</td>\n",
       "      <td>4890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks     0     1\n",
       "Actual attacks               \n",
       "0                  9432   279\n",
       "1                  2570  4890"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_DoS_pred2=clf_rfeDoS.predict(X_DoS_test2)\n",
    "\n",
    "pd.crosstab(Y_DoS_test, Y_DoS_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "concerned-proportion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2386</td>\n",
       "      <td>7325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "      <td>2345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks     0     2\n",
       "Actual attacks               \n",
       "0                  2386  7325\n",
       "2                    76  2345"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Probe_pred2=clf_rfeProbe.predict(X_Probe_test2)\n",
    "\n",
    "pd.crosstab(Y_Probe_test, Y_Probe_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "polish-creativity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9706</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks     0  3\n",
       "Actual attacks            \n",
       "0                  9706  5\n",
       "3                  2885  0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_R2L_pred2=clf_rfeR2L.predict(X_R2L_test2)\n",
    "\n",
    "pd.crosstab(Y_R2L_test, Y_R2L_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "respiratory-peripheral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9705</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks     0   4\n",
       "Actual attacks             \n",
       "0                  9705   6\n",
       "4                    56  11"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_U2R_pred2=clf_rfeU2R.predict(X_U2R_test2)\n",
    "\n",
    "pd.crosstab(Y_U2R_test, Y_U2R_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "secure-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "charged-aspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87722 (+/- 0.01139)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeNormal, X_Normal_test2, Y_Normal_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "healthy-paraguay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97851 (+/- 0.00509)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "#precision = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=10, scoring='precision')\n",
    "#print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "#recall = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=10, scoring='recall')\n",
    "#print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "#f = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=10, scoring='f1')\n",
    "#print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "level-freeze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97437 (+/- 0.00760)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "#precision = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=10, scoring='precision_macro')\n",
    "#print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "#recall = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=10, scoring='recall_macro')\n",
    "#print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "#f = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=10, scoring='f1_macro')\n",
    "#print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "after-recipient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94482 (+/- 0.00987)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "#precision = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=10, scoring='precision_macro')\n",
    "#print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "#recall = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=10, scoring='recall_macro')\n",
    "#print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "#f = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=10, scoring='f1_macro')\n",
    "#print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "incident-elimination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99611 (+/- 0.00170)\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 1))\n",
    "#precision = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=10, scoring='precision_macro')\n",
    "#print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "#recall = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=10, scoring='recall_macro')\n",
    "#print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "#f = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=10, scoring='f1_macro')\n",
    "#print(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "attempted-unknown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Whole Accuracy = \n",
      "0.9480000000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of Whole Accuracy = \")\n",
    "print(((0.99 + 0.94 + 0.97 + 0.97 + 0.87)/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-button",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
